{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmek6i8SXLxt",
        "outputId": "d47483dc-5f79-4bbb-8e47-b1aae029cb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1021\n",
            "Training samples: 816\n",
            "Testing samples: 205\n",
            "Model accuracy: 0.8292682926829268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-c0bf3651eb19>:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Profitable'] = data['Profitable'].astype(int)\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, time\n",
        "from pytz import timezone\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Fetch data from Yahoo Finance\n",
        "symbol = \"AMD\"\n",
        "amd = yf.Ticker(symbol)\n",
        "pacific = timezone('America/Los_Angeles')\n",
        "today_pacific = datetime.now(pacific)\n",
        "thirty_days_ago_pacific = today_pacific - timedelta(days=59)\n",
        "data = amd.history(interval='15m', start=thirty_days_ago_pacific, end=today_pacific)\n",
        "\n",
        "# Identify first 3 hours of trading (9:30 AM to 12:30 PM)\n",
        "market_open = time(6, 30)\n",
        "first_3_hours = [t for t in data.index if market_open <= t.time() <= time(15, 30)]\n",
        "\n",
        "# Add basic features\n",
        "data['Hour'] = data.index.hour\n",
        "data['Minute'] = data.index.minute\n",
        "\n",
        "\n",
        "data['PriceRange'] = data['High'] - data['Low']\n",
        "data['AveragePrice'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
        "data['MovingAverage'] = data['Close'].rolling(window=3).mean().fillna(data['Close'])\n",
        "\n",
        "# Add lag features\n",
        "for lag in range(1, 4):\n",
        "    data[f'PriceRange_lag{lag}'] = data['PriceRange'].shift(lag)\n",
        "    data[f'AveragePrice_lag{lag}'] = data['AveragePrice'].shift(lag)\n",
        "    data[f'MovingAverage_lag{lag}'] = data['MovingAverage'].shift(lag)\n",
        "\n",
        "\n",
        "\n",
        "data['Returns'] = data['Close'].pct_change()\n",
        "data['PriceChange'] = data['Close'].diff()\n",
        "data['Volatility'] = data['Close'].rolling(window=5).std()\n",
        "data['Volume'] = amd.history(interval='15m', start=thirty_days_ago_pacific, end=today_pacific)['Volume']\n",
        "data['PercentIncrease'] = data['Close'].pct_change() * 100\n",
        "\n",
        "ordered_columns = [\n",
        "    'Hour', 'Minute',\n",
        "    'PriceRange_lag1', 'AveragePrice_lag1', 'MovingAverage_lag1',\n",
        "    'PriceRange_lag2', 'AveragePrice_lag2', 'MovingAverage_lag2',\n",
        "    'PriceRange_lag3', 'AveragePrice_lag3', 'MovingAverage_lag3',\n",
        "    'PriceRange', 'AveragePrice', 'MovingAverage',\n",
        "    'Returns', 'PriceChange', 'Volatility', 'Volume', 'PercentIncrease'\n",
        "]\n",
        "\n",
        "data = data[ordered_columns]  # Reorder the DataFrame columns\n",
        "\n",
        "\n",
        "# Determine if profit can be made within the next 2 hours\n",
        "def profitable_within_next_4_hours(df, start_time):\n",
        "    end_time = min(start_time + timedelta(hours=2), start_time.replace(hour=16, minute=0))\n",
        "    relevant_data = df[(df.index > start_time) & (df.index <= end_time)]\n",
        "    if not relevant_data.empty:\n",
        "        return relevant_data['MovingAverage'].max() - df.at[start_time, 'MovingAverage'] >= 1\n",
        "    return False\n",
        "\n",
        "first_3_hours_df = data.loc[first_3_hours]\n",
        "first_3_hours_df['Profitable'] = [profitable_within_next_4_hours(data, t) for t in first_3_hours_df.index]\n",
        "\n",
        "# Merge with the original data\n",
        "data['Profitable'] = np.nan\n",
        "data['Profitable'] = first_3_hours_df['Profitable'].combine_first(data['Profitable'])\n",
        "data = data.dropna()\n",
        "\n",
        "# Convert labels to binary\n",
        "data['Profitable'] = data['Profitable'].astype(int)\n",
        "\n",
        "# Build pipeline and train model\n",
        "# Update feature list\n",
        "features = ['Hour', 'Minute',\n",
        "    'PriceRange_lag1', 'AveragePrice_lag1', 'MovingAverage_lag1',\n",
        "    'PriceRange_lag2', 'AveragePrice_lag2', 'MovingAverage_lag2',\n",
        "    'PriceRange_lag3', 'AveragePrice_lag3', 'MovingAverage_lag3',\n",
        "    'PriceRange', 'AveragePrice', 'MovingAverage',\n",
        "    'Returns', 'PriceChange', 'Volatility', 'Volume', 'PercentIncrease']\n",
        "\n",
        "X = data[features]\n",
        "y = data['Profitable']\n",
        "\n",
        "# Adjust test size if necessary\n",
        "test_size = min(0.2, max(1 / len(X), 0.2))\n",
        "\n",
        "# Re-split and re-train the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
        "\n",
        "# Rebuild the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Number of samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(f\"Model accuracy: {pipeline.score(X_test, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B_xRtz5OXPxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31a447f-b166-4725-cf1a-ef1df5bfca7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16961 (66.25 KB)\n",
            "Trainable params: 16961 (66.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "34/34 [==============================] - 5s 34ms/step - loss: 0.6899 - accuracy: 0.5310 - precision: 0.5333 - recall: 0.5103 - auc: 0.5488 - val_loss: 0.6547 - val_accuracy: 0.6966 - val_precision: 0.8732 - val_recall: 0.4627 - val_auc: 0.8579\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.6384 - accuracy: 0.6466 - precision: 0.6674 - recall: 0.5872 - auc: 0.7002 - val_loss: 0.5647 - val_accuracy: 0.7603 - val_precision: 0.7059 - val_recall: 0.8955 - val_auc: 0.8569\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5670 - accuracy: 0.7152 - precision: 0.7178 - recall: 0.7111 - auc: 0.7792 - val_loss: 0.4897 - val_accuracy: 0.7828 - val_precision: 0.7639 - val_recall: 0.8209 - val_auc: 0.8532\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5720 - accuracy: 0.7133 - precision: 0.7167 - recall: 0.7073 - auc: 0.7733 - val_loss: 0.4950 - val_accuracy: 0.7865 - val_precision: 0.7692 - val_recall: 0.8209 - val_auc: 0.8566\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5450 - accuracy: 0.7143 - precision: 0.7048 - recall: 0.7392 - auc: 0.8010 - val_loss: 0.4765 - val_accuracy: 0.7865 - val_precision: 0.7852 - val_recall: 0.7910 - val_auc: 0.8568\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5342 - accuracy: 0.7293 - precision: 0.7360 - recall: 0.7167 - auc: 0.8082 - val_loss: 0.4845 - val_accuracy: 0.7828 - val_precision: 0.7603 - val_recall: 0.8284 - val_auc: 0.8577\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5474 - accuracy: 0.7171 - precision: 0.7248 - recall: 0.7017 - auc: 0.7958 - val_loss: 0.4792 - val_accuracy: 0.8052 - val_precision: 0.8306 - val_recall: 0.7687 - val_auc: 0.8582\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5278 - accuracy: 0.7312 - precision: 0.7436 - recall: 0.7073 - auc: 0.8140 - val_loss: 0.4820 - val_accuracy: 0.7903 - val_precision: 0.7635 - val_recall: 0.8433 - val_auc: 0.8589\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5320 - accuracy: 0.7425 - precision: 0.7476 - recall: 0.7336 - auc: 0.8113 - val_loss: 0.4751 - val_accuracy: 0.8015 - val_precision: 0.8240 - val_recall: 0.7687 - val_auc: 0.8582\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.7359 - precision: 0.7490 - recall: 0.7111 - auc: 0.8099 - val_loss: 0.4714 - val_accuracy: 0.8052 - val_precision: 0.8106 - val_recall: 0.7985 - val_auc: 0.8608\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5247 - accuracy: 0.7321 - precision: 0.7375 - recall: 0.7223 - auc: 0.8151 - val_loss: 0.4762 - val_accuracy: 0.8052 - val_precision: 0.8417 - val_recall: 0.7537 - val_auc: 0.8588\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.5383 - accuracy: 0.7190 - precision: 0.7208 - recall: 0.7167 - auc: 0.8052 - val_loss: 0.4910 - val_accuracy: 0.8015 - val_precision: 0.7718 - val_recall: 0.8582 - val_auc: 0.8598\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.5237 - accuracy: 0.7340 - precision: 0.7422 - recall: 0.7186 - auc: 0.8161 - val_loss: 0.4724 - val_accuracy: 0.8090 - val_precision: 0.8120 - val_recall: 0.8060 - val_auc: 0.8581\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.5231 - accuracy: 0.7368 - precision: 0.7476 - recall: 0.7167 - auc: 0.8172 - val_loss: 0.4754 - val_accuracy: 0.8052 - val_precision: 0.7971 - val_recall: 0.8209 - val_auc: 0.8580\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 0.5234 - accuracy: 0.7312 - precision: 0.7300 - recall: 0.7355 - auc: 0.8160 - val_loss: 0.4763 - val_accuracy: 0.8052 - val_precision: 0.8306 - val_recall: 0.7687 - val_auc: 0.8576\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 1s 30ms/step - loss: 0.5317 - accuracy: 0.7274 - precision: 0.7332 - recall: 0.7167 - auc: 0.8121 - val_loss: 0.4896 - val_accuracy: 0.7978 - val_precision: 0.7597 - val_recall: 0.8731 - val_auc: 0.8589\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 0.5202 - accuracy: 0.7274 - precision: 0.7181 - recall: 0.7505 - auc: 0.8196 - val_loss: 0.4710 - val_accuracy: 0.7940 - val_precision: 0.8110 - val_recall: 0.7687 - val_auc: 0.8585\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 0.5207 - accuracy: 0.7406 - precision: 0.7545 - recall: 0.7148 - auc: 0.8191 - val_loss: 0.4765 - val_accuracy: 0.8015 - val_precision: 0.7755 - val_recall: 0.8507 - val_auc: 0.8597\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 0.5135 - accuracy: 0.7425 - precision: 0.7486 - recall: 0.7317 - auc: 0.8240 - val_loss: 0.4880 - val_accuracy: 0.7978 - val_precision: 0.7564 - val_recall: 0.8806 - val_auc: 0.8594\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.5178 - accuracy: 0.7340 - precision: 0.7193 - recall: 0.7692 - auc: 0.8214 - val_loss: 0.4791 - val_accuracy: 0.7940 - val_precision: 0.8319 - val_recall: 0.7388 - val_auc: 0.8594\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.5306 - accuracy: 0.7359 - precision: 0.7442 - recall: 0.7205 - auc: 0.8109 - val_loss: 0.4746 - val_accuracy: 0.7903 - val_precision: 0.8145 - val_recall: 0.7537 - val_auc: 0.8600\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5136 - accuracy: 0.7387 - precision: 0.7438 - recall: 0.7298 - auc: 0.8242 - val_loss: 0.4909 - val_accuracy: 0.7828 - val_precision: 0.7346 - val_recall: 0.8881 - val_auc: 0.8598\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5131 - accuracy: 0.7350 - precision: 0.7286 - recall: 0.7505 - auc: 0.8239 - val_loss: 0.4779 - val_accuracy: 0.7978 - val_precision: 0.7703 - val_recall: 0.8507 - val_auc: 0.8601\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5146 - accuracy: 0.7444 - precision: 0.7439 - recall: 0.7467 - auc: 0.8240 - val_loss: 0.4763 - val_accuracy: 0.8090 - val_precision: 0.8029 - val_recall: 0.8209 - val_auc: 0.8595\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5127 - accuracy: 0.7434 - precision: 0.7444 - recall: 0.7430 - auc: 0.8242 - val_loss: 0.4789 - val_accuracy: 0.8052 - val_precision: 0.7697 - val_recall: 0.8731 - val_auc: 0.8625\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5133 - accuracy: 0.7453 - precision: 0.7408 - recall: 0.7561 - auc: 0.8266 - val_loss: 0.4923 - val_accuracy: 0.7865 - val_precision: 0.8407 - val_recall: 0.7090 - val_auc: 0.8589\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5157 - accuracy: 0.7340 - precision: 0.7404 - recall: 0.7223 - auc: 0.8215 - val_loss: 0.4719 - val_accuracy: 0.8165 - val_precision: 0.8148 - val_recall: 0.8209 - val_auc: 0.8616\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5109 - accuracy: 0.7312 - precision: 0.7326 - recall: 0.7298 - auc: 0.8255 - val_loss: 0.4749 - val_accuracy: 0.7940 - val_precision: 0.7687 - val_recall: 0.8433 - val_auc: 0.8622\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.7312 - precision: 0.7343 - recall: 0.7261 - auc: 0.8303 - val_loss: 0.4887 - val_accuracy: 0.7715 - val_precision: 0.7212 - val_recall: 0.8881 - val_auc: 0.8630\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5061 - accuracy: 0.7368 - precision: 0.7347 - recall: 0.7430 - auc: 0.8294 - val_loss: 0.4766 - val_accuracy: 0.8090 - val_precision: 0.7943 - val_recall: 0.8358 - val_auc: 0.8609\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5124 - accuracy: 0.7491 - precision: 0.7529 - recall: 0.7430 - auc: 0.8258 - val_loss: 0.4691 - val_accuracy: 0.8165 - val_precision: 0.8244 - val_recall: 0.8060 - val_auc: 0.8644\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.7397 - precision: 0.7397 - recall: 0.7411 - auc: 0.8305 - val_loss: 0.4717 - val_accuracy: 0.8202 - val_precision: 0.8209 - val_recall: 0.8209 - val_auc: 0.8629\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.7406 - precision: 0.7495 - recall: 0.7242 - auc: 0.8318 - val_loss: 0.4738 - val_accuracy: 0.8052 - val_precision: 0.7733 - val_recall: 0.8657 - val_auc: 0.8657\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.5090 - accuracy: 0.7425 - precision: 0.7308 - recall: 0.7692 - auc: 0.8282 - val_loss: 0.4834 - val_accuracy: 0.7790 - val_precision: 0.7358 - val_recall: 0.8731 - val_auc: 0.8655\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.5064 - accuracy: 0.7444 - precision: 0.7495 - recall: 0.7355 - auc: 0.8291 - val_loss: 0.4664 - val_accuracy: 0.8127 - val_precision: 0.8231 - val_recall: 0.7985 - val_auc: 0.8640\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.5013 - accuracy: 0.7444 - precision: 0.7524 - recall: 0.7298 - auc: 0.8330 - val_loss: 0.4687 - val_accuracy: 0.8165 - val_precision: 0.8058 - val_recall: 0.8358 - val_auc: 0.8649\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.5046 - accuracy: 0.7368 - precision: 0.7428 - recall: 0.7261 - auc: 0.8310 - val_loss: 0.4684 - val_accuracy: 0.8240 - val_precision: 0.8222 - val_recall: 0.8284 - val_auc: 0.8650\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.5028 - accuracy: 0.7472 - precision: 0.7578 - recall: 0.7280 - auc: 0.8314 - val_loss: 0.4685 - val_accuracy: 0.8202 - val_precision: 0.8028 - val_recall: 0.8507 - val_auc: 0.8658\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.4952 - accuracy: 0.7500 - precision: 0.7514 - recall: 0.7486 - auc: 0.8381 - val_loss: 0.4665 - val_accuracy: 0.8165 - val_precision: 0.8148 - val_recall: 0.8209 - val_auc: 0.8668\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4989 - accuracy: 0.7472 - precision: 0.7619 - recall: 0.7205 - auc: 0.8346 - val_loss: 0.4647 - val_accuracy: 0.8202 - val_precision: 0.8116 - val_recall: 0.8358 - val_auc: 0.8684\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.7472 - precision: 0.7619 - recall: 0.7205 - auc: 0.8327 - val_loss: 0.4644 - val_accuracy: 0.8090 - val_precision: 0.7902 - val_recall: 0.8433 - val_auc: 0.8681\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4952 - accuracy: 0.7444 - precision: 0.7505 - recall: 0.7336 - auc: 0.8365 - val_loss: 0.4578 - val_accuracy: 0.8127 - val_precision: 0.8043 - val_recall: 0.8284 - val_auc: 0.8704\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4936 - accuracy: 0.7500 - precision: 0.7495 - recall: 0.7523 - auc: 0.8374 - val_loss: 0.4596 - val_accuracy: 0.8165 - val_precision: 0.8148 - val_recall: 0.8209 - val_auc: 0.8691\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.7538 - precision: 0.7581 - recall: 0.7467 - auc: 0.8370 - val_loss: 0.4673 - val_accuracy: 0.8127 - val_precision: 0.7917 - val_recall: 0.8507 - val_auc: 0.8672\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4994 - accuracy: 0.7331 - precision: 0.7310 - recall: 0.7392 - auc: 0.8328 - val_loss: 0.4585 - val_accuracy: 0.8202 - val_precision: 0.8071 - val_recall: 0.8433 - val_auc: 0.8708\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4896 - accuracy: 0.7472 - precision: 0.7568 - recall: 0.7298 - auc: 0.8396 - val_loss: 0.4602 - val_accuracy: 0.8165 - val_precision: 0.7972 - val_recall: 0.8507 - val_auc: 0.8697\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4965 - accuracy: 0.7350 - precision: 0.7400 - recall: 0.7261 - auc: 0.8341 - val_loss: 0.4568 - val_accuracy: 0.8165 - val_precision: 0.7972 - val_recall: 0.8507 - val_auc: 0.8730\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4915 - accuracy: 0.7434 - precision: 0.7407 - recall: 0.7505 - auc: 0.8373 - val_loss: 0.4715 - val_accuracy: 0.7903 - val_precision: 0.8197 - val_recall: 0.7463 - val_auc: 0.8668\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.5045 - accuracy: 0.7434 - precision: 0.7490 - recall: 0.7336 - auc: 0.8294 - val_loss: 0.4717 - val_accuracy: 0.7715 - val_precision: 0.7296 - val_recall: 0.8657 - val_auc: 0.8685\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4951 - accuracy: 0.7509 - precision: 0.7548 - recall: 0.7448 - auc: 0.8368 - val_loss: 0.4840 - val_accuracy: 0.7303 - val_precision: 0.6761 - val_recall: 0.8881 - val_auc: 0.8712\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.7425 - precision: 0.7367 - recall: 0.7561 - auc: 0.8309 - val_loss: 0.4540 - val_accuracy: 0.7865 - val_precision: 0.8182 - val_recall: 0.7388 - val_auc: 0.8726\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4826 - accuracy: 0.7481 - precision: 0.7613 - recall: 0.7242 - auc: 0.8439 - val_loss: 0.4504 - val_accuracy: 0.7978 - val_precision: 0.8226 - val_recall: 0.7612 - val_auc: 0.8726\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4879 - accuracy: 0.7444 - precision: 0.7458 - recall: 0.7430 - auc: 0.8398 - val_loss: 0.4544 - val_accuracy: 0.8127 - val_precision: 0.8231 - val_recall: 0.7985 - val_auc: 0.8700\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4836 - accuracy: 0.7453 - precision: 0.7620 - recall: 0.7148 - auc: 0.8427 - val_loss: 0.4752 - val_accuracy: 0.7341 - val_precision: 0.6800 - val_recall: 0.8881 - val_auc: 0.8731\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4941 - accuracy: 0.7528 - precision: 0.7509 - recall: 0.7580 - auc: 0.8367 - val_loss: 0.4561 - val_accuracy: 0.7978 - val_precision: 0.7740 - val_recall: 0.8433 - val_auc: 0.8697\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4819 - accuracy: 0.7594 - precision: 0.7618 - recall: 0.7561 - auc: 0.8448 - val_loss: 0.4578 - val_accuracy: 0.8277 - val_precision: 0.8235 - val_recall: 0.8358 - val_auc: 0.8727\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4841 - accuracy: 0.7462 - precision: 0.7505 - recall: 0.7392 - auc: 0.8409 - val_loss: 0.4570 - val_accuracy: 0.8090 - val_precision: 0.7943 - val_recall: 0.8358 - val_auc: 0.8715\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4772 - accuracy: 0.7462 - precision: 0.7553 - recall: 0.7298 - auc: 0.8474 - val_loss: 0.4511 - val_accuracy: 0.8127 - val_precision: 0.8088 - val_recall: 0.8209 - val_auc: 0.8720\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.7622 - precision: 0.7583 - recall: 0.7711 - auc: 0.8456 - val_loss: 0.4629 - val_accuracy: 0.7603 - val_precision: 0.7134 - val_recall: 0.8731 - val_auc: 0.8717\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4748 - accuracy: 0.7566 - precision: 0.7556 - recall: 0.7598 - auc: 0.8471 - val_loss: 0.4450 - val_accuracy: 0.7940 - val_precision: 0.8160 - val_recall: 0.7612 - val_auc: 0.8742\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4833 - accuracy: 0.7444 - precision: 0.7564 - recall: 0.7223 - auc: 0.8414 - val_loss: 0.4440 - val_accuracy: 0.8165 - val_precision: 0.8102 - val_recall: 0.8284 - val_auc: 0.8747\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.4797 - accuracy: 0.7415 - precision: 0.7354 - recall: 0.7561 - auc: 0.8440 - val_loss: 0.4522 - val_accuracy: 0.7940 - val_precision: 0.7687 - val_recall: 0.8433 - val_auc: 0.8727\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4738 - accuracy: 0.7519 - precision: 0.7552 - recall: 0.7467 - auc: 0.8470 - val_loss: 0.4525 - val_accuracy: 0.8202 - val_precision: 0.8116 - val_recall: 0.8358 - val_auc: 0.8713\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4757 - accuracy: 0.7650 - precision: 0.7706 - recall: 0.7561 - auc: 0.8469 - val_loss: 0.4390 - val_accuracy: 0.8090 - val_precision: 0.8029 - val_recall: 0.8209 - val_auc: 0.8763\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4753 - accuracy: 0.7406 - precision: 0.7402 - recall: 0.7430 - auc: 0.8458 - val_loss: 0.4680 - val_accuracy: 0.7378 - val_precision: 0.6882 - val_recall: 0.8731 - val_auc: 0.8724\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4756 - accuracy: 0.7538 - precision: 0.7561 - recall: 0.7505 - auc: 0.8451 - val_loss: 0.4563 - val_accuracy: 0.8165 - val_precision: 0.8102 - val_recall: 0.8284 - val_auc: 0.8710\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4778 - accuracy: 0.7547 - precision: 0.7519 - recall: 0.7617 - auc: 0.8467 - val_loss: 0.4543 - val_accuracy: 0.7640 - val_precision: 0.7290 - val_recall: 0.8433 - val_auc: 0.8694\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4747 - accuracy: 0.7491 - precision: 0.7481 - recall: 0.7523 - auc: 0.8463 - val_loss: 0.4530 - val_accuracy: 0.7903 - val_precision: 0.7566 - val_recall: 0.8582 - val_auc: 0.8735\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4722 - accuracy: 0.7519 - precision: 0.7572 - recall: 0.7430 - auc: 0.8496 - val_loss: 0.4598 - val_accuracy: 0.8090 - val_precision: 0.8168 - val_recall: 0.7985 - val_auc: 0.8713\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4848 - accuracy: 0.7566 - precision: 0.7645 - recall: 0.7430 - auc: 0.8437 - val_loss: 0.4720 - val_accuracy: 0.7378 - val_precision: 0.6905 - val_recall: 0.8657 - val_auc: 0.8685\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4901 - accuracy: 0.7453 - precision: 0.7435 - recall: 0.7505 - auc: 0.8361 - val_loss: 0.4451 - val_accuracy: 0.8127 - val_precision: 0.8043 - val_recall: 0.8284 - val_auc: 0.8736\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4712 - accuracy: 0.7491 - precision: 0.7529 - recall: 0.7430 - auc: 0.8489 - val_loss: 0.4483 - val_accuracy: 0.7640 - val_precision: 0.7233 - val_recall: 0.8582 - val_auc: 0.8755\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4769 - accuracy: 0.7528 - precision: 0.7377 - recall: 0.7861 - auc: 0.8484 - val_loss: 0.4392 - val_accuracy: 0.8277 - val_precision: 0.8284 - val_recall: 0.8284 - val_auc: 0.8764\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4867 - accuracy: 0.7519 - precision: 0.7728 - recall: 0.7148 - auc: 0.8409 - val_loss: 0.4574 - val_accuracy: 0.7790 - val_precision: 0.7451 - val_recall: 0.8507 - val_auc: 0.8738\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4784 - accuracy: 0.7491 - precision: 0.7418 - recall: 0.7655 - auc: 0.8438 - val_loss: 0.4476 - val_accuracy: 0.7715 - val_precision: 0.7325 - val_recall: 0.8582 - val_auc: 0.8753\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4804 - accuracy: 0.7387 - precision: 0.7447 - recall: 0.7280 - auc: 0.8424 - val_loss: 0.4431 - val_accuracy: 0.8052 - val_precision: 0.8306 - val_recall: 0.7687 - val_auc: 0.8743\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4698 - accuracy: 0.7519 - precision: 0.7514 - recall: 0.7542 - auc: 0.8493 - val_loss: 0.4434 - val_accuracy: 0.8277 - val_precision: 0.8235 - val_recall: 0.8358 - val_auc: 0.8742\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4726 - accuracy: 0.7509 - precision: 0.7384 - recall: 0.7786 - auc: 0.8473 - val_loss: 0.4409 - val_accuracy: 0.8165 - val_precision: 0.8148 - val_recall: 0.8209 - val_auc: 0.8721\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4686 - accuracy: 0.7547 - precision: 0.7720 - recall: 0.7242 - auc: 0.8491 - val_loss: 0.4465 - val_accuracy: 0.7715 - val_precision: 0.7355 - val_recall: 0.8507 - val_auc: 0.8740\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4710 - accuracy: 0.7425 - precision: 0.7439 - recall: 0.7411 - auc: 0.8477 - val_loss: 0.4663 - val_accuracy: 0.7341 - val_precision: 0.6821 - val_recall: 0.8806 - val_auc: 0.8740\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4751 - accuracy: 0.7406 - precision: 0.7332 - recall: 0.7580 - auc: 0.8452 - val_loss: 0.4429 - val_accuracy: 0.8090 - val_precision: 0.7943 - val_recall: 0.8358 - val_auc: 0.8721\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4639 - accuracy: 0.7566 - precision: 0.7455 - recall: 0.7805 - auc: 0.8535 - val_loss: 0.4403 - val_accuracy: 0.7865 - val_precision: 0.7619 - val_recall: 0.8358 - val_auc: 0.8735\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4730 - accuracy: 0.7462 - precision: 0.7524 - recall: 0.7355 - auc: 0.8446 - val_loss: 0.4526 - val_accuracy: 0.7566 - val_precision: 0.7226 - val_recall: 0.8358 - val_auc: 0.8700\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4669 - accuracy: 0.7491 - precision: 0.7472 - recall: 0.7542 - auc: 0.8486 - val_loss: 0.4471 - val_accuracy: 0.8165 - val_precision: 0.8148 - val_recall: 0.8209 - val_auc: 0.8716\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4630 - accuracy: 0.7585 - precision: 0.7518 - recall: 0.7730 - auc: 0.8518 - val_loss: 0.4540 - val_accuracy: 0.7528 - val_precision: 0.7073 - val_recall: 0.8657 - val_auc: 0.8748\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.4795 - accuracy: 0.7481 - precision: 0.7387 - recall: 0.7692 - auc: 0.8426 - val_loss: 0.4379 - val_accuracy: 0.8090 - val_precision: 0.7943 - val_recall: 0.8358 - val_auc: 0.8761\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4702 - accuracy: 0.7481 - precision: 0.7553 - recall: 0.7355 - auc: 0.8481 - val_loss: 0.4495 - val_accuracy: 0.7865 - val_precision: 0.7619 - val_recall: 0.8358 - val_auc: 0.8732\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.4656 - accuracy: 0.7509 - precision: 0.7519 - recall: 0.7505 - auc: 0.8504 - val_loss: 0.4582 - val_accuracy: 0.7753 - val_precision: 0.7372 - val_recall: 0.8582 - val_auc: 0.8713\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.4704 - accuracy: 0.7509 - precision: 0.7519 - recall: 0.7505 - auc: 0.8490 - val_loss: 0.4451 - val_accuracy: 0.7640 - val_precision: 0.7261 - val_recall: 0.8507 - val_auc: 0.8735\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4616 - accuracy: 0.7509 - precision: 0.7472 - recall: 0.7598 - auc: 0.8530 - val_loss: 0.4611 - val_accuracy: 0.7940 - val_precision: 0.7842 - val_recall: 0.8134 - val_auc: 0.8689\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.4702 - accuracy: 0.7566 - precision: 0.7655 - recall: 0.7411 - auc: 0.8477 - val_loss: 0.4366 - val_accuracy: 0.7865 - val_precision: 0.7619 - val_recall: 0.8358 - val_auc: 0.8752\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4639 - accuracy: 0.7491 - precision: 0.7427 - recall: 0.7636 - auc: 0.8510 - val_loss: 0.4472 - val_accuracy: 0.7865 - val_precision: 0.7655 - val_recall: 0.8284 - val_auc: 0.8697\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4692 - accuracy: 0.7491 - precision: 0.7418 - recall: 0.7655 - auc: 0.8491 - val_loss: 0.4374 - val_accuracy: 0.7753 - val_precision: 0.7434 - val_recall: 0.8433 - val_auc: 0.8746\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4616 - accuracy: 0.7650 - precision: 0.7780 - recall: 0.7430 - auc: 0.8556 - val_loss: 0.4412 - val_accuracy: 0.7828 - val_precision: 0.7603 - val_recall: 0.8284 - val_auc: 0.8737\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4619 - accuracy: 0.7500 - precision: 0.7459 - recall: 0.7598 - auc: 0.8518 - val_loss: 0.4356 - val_accuracy: 0.7753 - val_precision: 0.7403 - val_recall: 0.8507 - val_auc: 0.8766\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.7415 - precision: 0.7407 - recall: 0.7448 - auc: 0.8431 - val_loss: 0.4315 - val_accuracy: 0.7978 - val_precision: 0.8125 - val_recall: 0.7761 - val_auc: 0.8758\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4622 - accuracy: 0.7547 - precision: 0.7537 - recall: 0.7580 - auc: 0.8531 - val_loss: 0.4322 - val_accuracy: 0.8015 - val_precision: 0.7872 - val_recall: 0.8284 - val_auc: 0.8777\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4649 - accuracy: 0.7650 - precision: 0.7748 - recall: 0.7486 - auc: 0.8530 - val_loss: 0.4471 - val_accuracy: 0.8090 - val_precision: 0.8320 - val_recall: 0.7761 - val_auc: 0.8741\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4631 - accuracy: 0.7575 - precision: 0.7505 - recall: 0.7730 - auc: 0.8535 - val_loss: 0.4314 - val_accuracy: 0.8090 - val_precision: 0.8029 - val_recall: 0.8209 - val_auc: 0.8782\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4607 - accuracy: 0.7519 - precision: 0.7552 - recall: 0.7467 - auc: 0.8544 - val_loss: 0.4470 - val_accuracy: 0.7566 - val_precision: 0.7117 - val_recall: 0.8657 - val_auc: 0.8736\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4664 - accuracy: 0.7538 - precision: 0.7332 - recall: 0.7992 - auc: 0.8496 - val_loss: 0.4433 - val_accuracy: 0.8052 - val_precision: 0.7971 - val_recall: 0.8209 - val_auc: 0.8764\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4621 - accuracy: 0.7632 - precision: 0.7646 - recall: 0.7617 - auc: 0.8549 - val_loss: 0.4612 - val_accuracy: 0.7416 - val_precision: 0.6879 - val_recall: 0.8881 - val_auc: 0.8743\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4637 - accuracy: 0.7594 - precision: 0.7505 - recall: 0.7786 - auc: 0.8516 - val_loss: 0.4398 - val_accuracy: 0.8052 - val_precision: 0.8015 - val_recall: 0.8134 - val_auc: 0.8742\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4550 - accuracy: 0.7575 - precision: 0.7477 - recall: 0.7786 - auc: 0.8576 - val_loss: 0.4364 - val_accuracy: 0.7978 - val_precision: 0.7817 - val_recall: 0.8284 - val_auc: 0.8749\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.7528 - precision: 0.7567 - recall: 0.7467 - auc: 0.8549 - val_loss: 0.4467 - val_accuracy: 0.7940 - val_precision: 0.8264 - val_recall: 0.7463 - val_auc: 0.8777\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4781 - accuracy: 0.7509 - precision: 0.7567 - recall: 0.7411 - auc: 0.8440 - val_loss: 0.4349 - val_accuracy: 0.7828 - val_precision: 0.7568 - val_recall: 0.8358 - val_auc: 0.8770\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4617 - accuracy: 0.7566 - precision: 0.7645 - recall: 0.7430 - auc: 0.8529 - val_loss: 0.4303 - val_accuracy: 0.7790 - val_precision: 0.7483 - val_recall: 0.8433 - val_auc: 0.8798\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4571 - accuracy: 0.7538 - precision: 0.7407 - recall: 0.7824 - auc: 0.8542 - val_loss: 0.4378 - val_accuracy: 0.7828 - val_precision: 0.7603 - val_recall: 0.8284 - val_auc: 0.8783\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4523 - accuracy: 0.7575 - precision: 0.7570 - recall: 0.7598 - auc: 0.8602 - val_loss: 0.4359 - val_accuracy: 0.7978 - val_precision: 0.7899 - val_recall: 0.8134 - val_auc: 0.8744\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.7519 - precision: 0.7486 - recall: 0.7598 - auc: 0.8548 - val_loss: 0.4274 - val_accuracy: 0.8015 - val_precision: 0.8045 - val_recall: 0.7985 - val_auc: 0.8775\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4559 - accuracy: 0.7613 - precision: 0.7550 - recall: 0.7749 - auc: 0.8568 - val_loss: 0.4400 - val_accuracy: 0.8015 - val_precision: 0.8140 - val_recall: 0.7836 - val_auc: 0.8775\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4575 - accuracy: 0.7603 - precision: 0.7715 - recall: 0.7411 - auc: 0.8564 - val_loss: 0.4402 - val_accuracy: 0.7640 - val_precision: 0.7205 - val_recall: 0.8657 - val_auc: 0.8770\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.4655 - accuracy: 0.7444 - precision: 0.7254 - recall: 0.7880 - auc: 0.8490 - val_loss: 0.4362 - val_accuracy: 0.7790 - val_precision: 0.7517 - val_recall: 0.8358 - val_auc: 0.8754\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4683 - accuracy: 0.7566 - precision: 0.7686 - recall: 0.7355 - auc: 0.8483 - val_loss: 0.4674 - val_accuracy: 0.7828 - val_precision: 0.7568 - val_recall: 0.8358 - val_auc: 0.8710\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4561 - accuracy: 0.7707 - precision: 0.7585 - recall: 0.7955 - auc: 0.8578 - val_loss: 0.4323 - val_accuracy: 0.8127 - val_precision: 0.8182 - val_recall: 0.8060 - val_auc: 0.8768\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4509 - accuracy: 0.7566 - precision: 0.7518 - recall: 0.7674 - auc: 0.8592 - val_loss: 0.4332 - val_accuracy: 0.7753 - val_precision: 0.7500 - val_recall: 0.8284 - val_auc: 0.8756\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4572 - accuracy: 0.7594 - precision: 0.7478 - recall: 0.7842 - auc: 0.8536 - val_loss: 0.4289 - val_accuracy: 0.7715 - val_precision: 0.7355 - val_recall: 0.8507 - val_auc: 0.8803\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4605 - accuracy: 0.7603 - precision: 0.7623 - recall: 0.7580 - auc: 0.8530 - val_loss: 0.4318 - val_accuracy: 0.7978 - val_precision: 0.7899 - val_recall: 0.8134 - val_auc: 0.8768\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4498 - accuracy: 0.7632 - precision: 0.7504 - recall: 0.7899 - auc: 0.8597 - val_loss: 0.4361 - val_accuracy: 0.7753 - val_precision: 0.7569 - val_recall: 0.8134 - val_auc: 0.8741\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4567 - accuracy: 0.7716 - precision: 0.7746 - recall: 0.7674 - auc: 0.8581 - val_loss: 0.4448 - val_accuracy: 0.7715 - val_precision: 0.7386 - val_recall: 0.8433 - val_auc: 0.8730\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4588 - accuracy: 0.7688 - precision: 0.7614 - recall: 0.7842 - auc: 0.8589 - val_loss: 0.4326 - val_accuracy: 0.8052 - val_precision: 0.8306 - val_recall: 0.7687 - val_auc: 0.8785\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4527 - accuracy: 0.7575 - precision: 0.7477 - recall: 0.7786 - auc: 0.8586 - val_loss: 0.4283 - val_accuracy: 0.7753 - val_precision: 0.7500 - val_recall: 0.8284 - val_auc: 0.8791\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4595 - accuracy: 0.7453 - precision: 0.7408 - recall: 0.7561 - auc: 0.8531 - val_loss: 0.4597 - val_accuracy: 0.7940 - val_precision: 0.7801 - val_recall: 0.8209 - val_auc: 0.8761\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4514 - accuracy: 0.7641 - precision: 0.7660 - recall: 0.7617 - auc: 0.8606 - val_loss: 0.4346 - val_accuracy: 0.7828 - val_precision: 0.7603 - val_recall: 0.8284 - val_auc: 0.8746\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4498 - accuracy: 0.7528 - precision: 0.7437 - recall: 0.7730 - auc: 0.8578 - val_loss: 0.4348 - val_accuracy: 0.7940 - val_precision: 0.7970 - val_recall: 0.7910 - val_auc: 0.8745\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4613 - accuracy: 0.7453 - precision: 0.7331 - recall: 0.7730 - auc: 0.8521 - val_loss: 0.4284 - val_accuracy: 0.7678 - val_precision: 0.7400 - val_recall: 0.8284 - val_auc: 0.8771\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4526 - accuracy: 0.7594 - precision: 0.7514 - recall: 0.7767 - auc: 0.8580 - val_loss: 0.4291 - val_accuracy: 0.7828 - val_precision: 0.7676 - val_recall: 0.8134 - val_auc: 0.8766\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4490 - accuracy: 0.7688 - precision: 0.7576 - recall: 0.7917 - auc: 0.8617 - val_loss: 0.4267 - val_accuracy: 0.7828 - val_precision: 0.7676 - val_recall: 0.8134 - val_auc: 0.8753\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4462 - accuracy: 0.7697 - precision: 0.7697 - recall: 0.7711 - auc: 0.8627 - val_loss: 0.4487 - val_accuracy: 0.7603 - val_precision: 0.7188 - val_recall: 0.8582 - val_auc: 0.8702\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4624 - accuracy: 0.7547 - precision: 0.7500 - recall: 0.7655 - auc: 0.8526 - val_loss: 0.4276 - val_accuracy: 0.7640 - val_precision: 0.7351 - val_recall: 0.8284 - val_auc: 0.8761\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4494 - accuracy: 0.7528 - precision: 0.7360 - recall: 0.7899 - auc: 0.8610 - val_loss: 0.4324 - val_accuracy: 0.7903 - val_precision: 0.8047 - val_recall: 0.7687 - val_auc: 0.8754\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4565 - accuracy: 0.7650 - precision: 0.7706 - recall: 0.7561 - auc: 0.8573 - val_loss: 0.4279 - val_accuracy: 0.7828 - val_precision: 0.7754 - val_recall: 0.7985 - val_auc: 0.8739\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4486 - accuracy: 0.7622 - precision: 0.7642 - recall: 0.7598 - auc: 0.8619 - val_loss: 0.4339 - val_accuracy: 0.7790 - val_precision: 0.7660 - val_recall: 0.8060 - val_auc: 0.8755\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4508 - accuracy: 0.7556 - precision: 0.7542 - recall: 0.7598 - auc: 0.8580 - val_loss: 0.4248 - val_accuracy: 0.7865 - val_precision: 0.7810 - val_recall: 0.7985 - val_auc: 0.8736\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4562 - accuracy: 0.7556 - precision: 0.7571 - recall: 0.7542 - auc: 0.8543 - val_loss: 0.4308 - val_accuracy: 0.7640 - val_precision: 0.7415 - val_recall: 0.8134 - val_auc: 0.8704\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.4501 - accuracy: 0.7791 - precision: 0.7651 - recall: 0.8068 - auc: 0.8616 - val_loss: 0.4441 - val_accuracy: 0.7678 - val_precision: 0.7400 - val_recall: 0.8284 - val_auc: 0.8711\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4509 - accuracy: 0.7763 - precision: 0.7667 - recall: 0.7955 - auc: 0.8630 - val_loss: 0.4346 - val_accuracy: 0.8015 - val_precision: 0.8240 - val_recall: 0.7687 - val_auc: 0.8710\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4535 - accuracy: 0.7585 - precision: 0.7644 - recall: 0.7486 - auc: 0.8594 - val_loss: 0.4359 - val_accuracy: 0.7603 - val_precision: 0.7215 - val_recall: 0.8507 - val_auc: 0.8743\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4558 - accuracy: 0.7566 - precision: 0.7556 - recall: 0.7598 - auc: 0.8569 - val_loss: 0.4314 - val_accuracy: 0.7753 - val_precision: 0.7534 - val_recall: 0.8209 - val_auc: 0.8762\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4582 - accuracy: 0.7660 - precision: 0.7448 - recall: 0.8105 - auc: 0.8595 - val_loss: 0.4344 - val_accuracy: 0.7790 - val_precision: 0.7778 - val_recall: 0.7836 - val_auc: 0.8701\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4513 - accuracy: 0.7688 - precision: 0.7733 - recall: 0.7617 - auc: 0.8591 - val_loss: 0.4293 - val_accuracy: 0.8015 - val_precision: 0.8092 - val_recall: 0.7910 - val_auc: 0.8748\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4475 - accuracy: 0.7754 - precision: 0.7743 - recall: 0.7786 - auc: 0.8642 - val_loss: 0.4298 - val_accuracy: 0.7678 - val_precision: 0.7432 - val_recall: 0.8209 - val_auc: 0.8747\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.4452 - accuracy: 0.7660 - precision: 0.7572 - recall: 0.7842 - auc: 0.8645 - val_loss: 0.4482 - val_accuracy: 0.7753 - val_precision: 0.7434 - val_recall: 0.8433 - val_auc: 0.8715\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4438 - accuracy: 0.7660 - precision: 0.7649 - recall: 0.7692 - auc: 0.8646 - val_loss: 0.4424 - val_accuracy: 0.7978 - val_precision: 0.7985 - val_recall: 0.7985 - val_auc: 0.8740\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4479 - accuracy: 0.7763 - precision: 0.7706 - recall: 0.7880 - auc: 0.8626 - val_loss: 0.4211 - val_accuracy: 0.8052 - val_precision: 0.8060 - val_recall: 0.8060 - val_auc: 0.8774\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.7650 - precision: 0.7685 - recall: 0.7598 - auc: 0.8624 - val_loss: 0.4402 - val_accuracy: 0.7828 - val_precision: 0.7639 - val_recall: 0.8209 - val_auc: 0.8745\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4413 - accuracy: 0.7773 - precision: 0.7824 - recall: 0.7692 - auc: 0.8648 - val_loss: 0.4438 - val_accuracy: 0.7491 - val_precision: 0.7107 - val_recall: 0.8433 - val_auc: 0.8724\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.7791 - precision: 0.7699 - recall: 0.7974 - auc: 0.8652 - val_loss: 0.4358 - val_accuracy: 0.7940 - val_precision: 0.7842 - val_recall: 0.8134 - val_auc: 0.8707\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4412 - accuracy: 0.7791 - precision: 0.7719 - recall: 0.7936 - auc: 0.8696 - val_loss: 0.4274 - val_accuracy: 0.7790 - val_precision: 0.7622 - val_recall: 0.8134 - val_auc: 0.8749\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4427 - accuracy: 0.7716 - precision: 0.7646 - recall: 0.7861 - auc: 0.8650 - val_loss: 0.4294 - val_accuracy: 0.7940 - val_precision: 0.7926 - val_recall: 0.7985 - val_auc: 0.8729\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4394 - accuracy: 0.7848 - precision: 0.7784 - recall: 0.7974 - auc: 0.8677 - val_loss: 0.4270 - val_accuracy: 0.7865 - val_precision: 0.7810 - val_recall: 0.7985 - val_auc: 0.8745\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4333 - accuracy: 0.7744 - precision: 0.7678 - recall: 0.7880 - auc: 0.8711 - val_loss: 0.4424 - val_accuracy: 0.7903 - val_precision: 0.7868 - val_recall: 0.7985 - val_auc: 0.8742\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4405 - accuracy: 0.7669 - precision: 0.7513 - recall: 0.7992 - auc: 0.8667 - val_loss: 0.4424 - val_accuracy: 0.7865 - val_precision: 0.8080 - val_recall: 0.7537 - val_auc: 0.8716\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4379 - accuracy: 0.7838 - precision: 0.7965 - recall: 0.7636 - auc: 0.8727 - val_loss: 0.4257 - val_accuracy: 0.7865 - val_precision: 0.7655 - val_recall: 0.8284 - val_auc: 0.8777\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4367 - accuracy: 0.7716 - precision: 0.7627 - recall: 0.7899 - auc: 0.8700 - val_loss: 0.4286 - val_accuracy: 0.7865 - val_precision: 0.7939 - val_recall: 0.7761 - val_auc: 0.8704\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4479 - accuracy: 0.7688 - precision: 0.7614 - recall: 0.7842 - auc: 0.8620 - val_loss: 0.4277 - val_accuracy: 0.7903 - val_precision: 0.7826 - val_recall: 0.8060 - val_auc: 0.8766\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4438 - accuracy: 0.7744 - precision: 0.7659 - recall: 0.7917 - auc: 0.8647 - val_loss: 0.4418 - val_accuracy: 0.7865 - val_precision: 0.8031 - val_recall: 0.7612 - val_auc: 0.8718\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4379 - accuracy: 0.7857 - precision: 0.7883 - recall: 0.7824 - auc: 0.8695 - val_loss: 0.4326 - val_accuracy: 0.7828 - val_precision: 0.7714 - val_recall: 0.8060 - val_auc: 0.8712\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4470 - accuracy: 0.7585 - precision: 0.7473 - recall: 0.7824 - auc: 0.8624 - val_loss: 0.4320 - val_accuracy: 0.7865 - val_precision: 0.8130 - val_recall: 0.7463 - val_auc: 0.8702\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4432 - accuracy: 0.7716 - precision: 0.7675 - recall: 0.7805 - auc: 0.8655 - val_loss: 0.4275 - val_accuracy: 0.7865 - val_precision: 0.7852 - val_recall: 0.7910 - val_auc: 0.8711\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4392 - accuracy: 0.7763 - precision: 0.7706 - recall: 0.7880 - auc: 0.8674 - val_loss: 0.4592 - val_accuracy: 0.7640 - val_precision: 0.7383 - val_recall: 0.8209 - val_auc: 0.8658\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4524 - accuracy: 0.7763 - precision: 0.7898 - recall: 0.7542 - auc: 0.8621 - val_loss: 0.4434 - val_accuracy: 0.7753 - val_precision: 0.7342 - val_recall: 0.8657 - val_auc: 0.8781\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4438 - accuracy: 0.7801 - precision: 0.7869 - recall: 0.7692 - auc: 0.8667 - val_loss: 0.4244 - val_accuracy: 0.7865 - val_precision: 0.7770 - val_recall: 0.8060 - val_auc: 0.8760\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4385 - accuracy: 0.7744 - precision: 0.7688 - recall: 0.7861 - auc: 0.8697 - val_loss: 0.4286 - val_accuracy: 0.7865 - val_precision: 0.7692 - val_recall: 0.8209 - val_auc: 0.8815\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4512 - accuracy: 0.7801 - precision: 0.7996 - recall: 0.7486 - auc: 0.8618 - val_loss: 0.4297 - val_accuracy: 0.7865 - val_precision: 0.7692 - val_recall: 0.8209 - val_auc: 0.8745\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 0.4439 - accuracy: 0.7810 - precision: 0.7708 - recall: 0.8011 - auc: 0.8664 - val_loss: 0.4292 - val_accuracy: 0.7940 - val_precision: 0.7801 - val_recall: 0.8209 - val_auc: 0.8774\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4385 - accuracy: 0.7791 - precision: 0.7822 - recall: 0.7749 - auc: 0.8684 - val_loss: 0.4372 - val_accuracy: 0.7790 - val_precision: 0.7586 - val_recall: 0.8209 - val_auc: 0.8696\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 0.4449 - accuracy: 0.7810 - precision: 0.7907 - recall: 0.7655 - auc: 0.8698 - val_loss: 0.4392 - val_accuracy: 0.7678 - val_precision: 0.7250 - val_recall: 0.8657 - val_auc: 0.8790\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.7876 - precision: 0.7766 - recall: 0.8086 - auc: 0.8693 - val_loss: 0.4256 - val_accuracy: 0.7865 - val_precision: 0.7619 - val_recall: 0.8358 - val_auc: 0.8776\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4334 - accuracy: 0.7904 - precision: 0.8016 - recall: 0.7730 - auc: 0.8734 - val_loss: 0.4293 - val_accuracy: 0.7678 - val_precision: 0.7368 - val_recall: 0.8358 - val_auc: 0.8743\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4318 - accuracy: 0.7782 - precision: 0.7807 - recall: 0.7749 - auc: 0.8735 - val_loss: 0.4459 - val_accuracy: 0.7640 - val_precision: 0.7290 - val_recall: 0.8433 - val_auc: 0.8715\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.7782 - precision: 0.7839 - recall: 0.7692 - auc: 0.8719 - val_loss: 0.4286 - val_accuracy: 0.7715 - val_precision: 0.7267 - val_recall: 0.8731 - val_auc: 0.8812\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.7707 - precision: 0.7711 - recall: 0.7711 - auc: 0.8710 - val_loss: 0.4271 - val_accuracy: 0.7790 - val_precision: 0.7451 - val_recall: 0.8507 - val_auc: 0.8808\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4314 - accuracy: 0.7773 - precision: 0.7814 - recall: 0.7711 - auc: 0.8715 - val_loss: 0.4256 - val_accuracy: 0.7903 - val_precision: 0.7786 - val_recall: 0.8134 - val_auc: 0.8727\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4393 - accuracy: 0.7754 - precision: 0.7743 - recall: 0.7786 - auc: 0.8703 - val_loss: 0.4234 - val_accuracy: 0.7865 - val_precision: 0.7770 - val_recall: 0.8060 - val_auc: 0.8750\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4421 - accuracy: 0.7744 - precision: 0.7718 - recall: 0.7805 - auc: 0.8660 - val_loss: 0.4357 - val_accuracy: 0.7903 - val_precision: 0.7786 - val_recall: 0.8134 - val_auc: 0.8692\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4315 - accuracy: 0.7838 - precision: 0.7811 - recall: 0.7899 - auc: 0.8750 - val_loss: 0.4338 - val_accuracy: 0.7865 - val_precision: 0.8080 - val_recall: 0.7537 - val_auc: 0.8695\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.7820 - precision: 0.7692 - recall: 0.8068 - auc: 0.8708 - val_loss: 0.4215 - val_accuracy: 0.7753 - val_precision: 0.7606 - val_recall: 0.8060 - val_auc: 0.8771\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4295 - accuracy: 0.7820 - precision: 0.7900 - recall: 0.7692 - auc: 0.8735 - val_loss: 0.4223 - val_accuracy: 0.7790 - val_precision: 0.7737 - val_recall: 0.7910 - val_auc: 0.8734\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.7791 - precision: 0.7833 - recall: 0.7730 - auc: 0.8799 - val_loss: 0.4170 - val_accuracy: 0.8090 - val_precision: 0.7902 - val_recall: 0.8433 - val_auc: 0.8798\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4344 - accuracy: 0.7791 - precision: 0.7759 - recall: 0.7861 - auc: 0.8736 - val_loss: 0.4203 - val_accuracy: 0.7715 - val_precision: 0.7786 - val_recall: 0.7612 - val_auc: 0.8751\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4282 - accuracy: 0.7838 - precision: 0.8024 - recall: 0.7542 - auc: 0.8748 - val_loss: 0.4273 - val_accuracy: 0.7715 - val_precision: 0.7417 - val_recall: 0.8358 - val_auc: 0.8786\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 0.4289 - accuracy: 0.7848 - precision: 0.7846 - recall: 0.7861 - auc: 0.8778 - val_loss: 0.4233 - val_accuracy: 0.7978 - val_precision: 0.7817 - val_recall: 0.8284 - val_auc: 0.8772\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4232 - accuracy: 0.7791 - precision: 0.7822 - recall: 0.7749 - auc: 0.8769 - val_loss: 0.4176 - val_accuracy: 0.7978 - val_precision: 0.7899 - val_recall: 0.8134 - val_auc: 0.8798\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4227 - accuracy: 0.7707 - precision: 0.7671 - recall: 0.7786 - auc: 0.8762 - val_loss: 0.4175 - val_accuracy: 0.7940 - val_precision: 0.7724 - val_recall: 0.8358 - val_auc: 0.8784\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4292 - accuracy: 0.7857 - precision: 0.7996 - recall: 0.7636 - auc: 0.8749 - val_loss: 0.4377 - val_accuracy: 0.7640 - val_precision: 0.7669 - val_recall: 0.7612 - val_auc: 0.8755\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 0.4236 - accuracy: 0.7791 - precision: 0.7719 - recall: 0.7936 - auc: 0.8771 - val_loss: 0.4331 - val_accuracy: 0.7640 - val_precision: 0.7630 - val_recall: 0.7687 - val_auc: 0.8733\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4330 - accuracy: 0.7791 - precision: 0.7801 - recall: 0.7786 - auc: 0.8700 - val_loss: 0.4241 - val_accuracy: 0.7828 - val_precision: 0.7879 - val_recall: 0.7761 - val_auc: 0.8803\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 0.4275 - accuracy: 0.7829 - precision: 0.7817 - recall: 0.7861 - auc: 0.8758 - val_loss: 0.4355 - val_accuracy: 0.7566 - val_precision: 0.7760 - val_recall: 0.7239 - val_auc: 0.8741\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4311 - accuracy: 0.7829 - precision: 0.7860 - recall: 0.7786 - auc: 0.8762 - val_loss: 0.4261 - val_accuracy: 0.7790 - val_precision: 0.7863 - val_recall: 0.7687 - val_auc: 0.8697\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 0.4284 - accuracy: 0.7707 - precision: 0.7774 - recall: 0.7598 - auc: 0.8740 - val_loss: 0.4307 - val_accuracy: 0.7940 - val_precision: 0.7842 - val_recall: 0.8134 - val_auc: 0.8732\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.4256 - accuracy: 0.7857 - precision: 0.7984 - recall: 0.7655 - auc: 0.8788 - val_loss: 0.4224 - val_accuracy: 0.7603 - val_precision: 0.7612 - val_recall: 0.7612 - val_auc: 0.8751\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4214 - accuracy: 0.7801 - precision: 0.7723 - recall: 0.7955 - auc: 0.8796 - val_loss: 0.4236 - val_accuracy: 0.7528 - val_precision: 0.7656 - val_recall: 0.7313 - val_auc: 0.8706\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4172 - accuracy: 0.7914 - precision: 0.8019 - recall: 0.7749 - auc: 0.8807 - val_loss: 0.4226 - val_accuracy: 0.7828 - val_precision: 0.7836 - val_recall: 0.7836 - val_auc: 0.8760\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4233 - accuracy: 0.7838 - precision: 0.7942 - recall: 0.7674 - auc: 0.8787 - val_loss: 0.4303 - val_accuracy: 0.7903 - val_precision: 0.7566 - val_recall: 0.8582 - val_auc: 0.8771\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 0.4330 - accuracy: 0.7857 - precision: 0.7927 - recall: 0.7749 - auc: 0.8732 - val_loss: 0.4170 - val_accuracy: 0.7715 - val_precision: 0.7704 - val_recall: 0.7761 - val_auc: 0.8750\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4204 - accuracy: 0.7848 - precision: 0.8052 - recall: 0.7523 - auc: 0.8799 - val_loss: 0.4273 - val_accuracy: 0.7903 - val_precision: 0.7826 - val_recall: 0.8060 - val_auc: 0.8728\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4276 - accuracy: 0.7726 - precision: 0.7730 - recall: 0.7730 - auc: 0.8742 - val_loss: 0.4306 - val_accuracy: 0.7940 - val_precision: 0.7762 - val_recall: 0.8284 - val_auc: 0.8707\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4225 - accuracy: 0.7810 - precision: 0.7874 - recall: 0.7711 - auc: 0.8807 - val_loss: 0.4209 - val_accuracy: 0.7753 - val_precision: 0.7534 - val_recall: 0.8209 - val_auc: 0.8777\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 0.4187 - accuracy: 0.7838 - precision: 0.7875 - recall: 0.7786 - auc: 0.8794 - val_loss: 0.4272 - val_accuracy: 0.7715 - val_precision: 0.7744 - val_recall: 0.7687 - val_auc: 0.8684\n",
            "11/11 [==============================] - 0s 4ms/step\n",
            "Test accuracy: 0.7447\n",
            "Precision: 0.7597\n",
            "Recall: 0.7091\n",
            "F1 Score: 0.7335\n",
            "ROC-AUC Score: 0.7444\n",
            "Confusion Matrix:\n",
            " [[131  37]\n",
            " [ 48 117]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.76       168\n",
            "           1       0.76      0.71      0.73       165\n",
            "\n",
            "    accuracy                           0.74       333\n",
            "   macro avg       0.75      0.74      0.74       333\n",
            "weighted avg       0.75      0.74      0.74       333\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Convert DataFrame X to a numpy array\n",
        "X_array = X.to_numpy()\n",
        "\n",
        "sequence_length = X.shape[1]\n",
        "num_features = X.shape[2] if X.ndim > 2 else 1\n",
        "\n",
        "# Reshape the numpy array\n",
        "X_res = X_array.reshape(-1, sequence_length * num_features)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_res, y)\n",
        "\n",
        "# Reshape back to original dimensions\n",
        "X_res = X_res.reshape(-1, sequence_length, num_features)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(sequence_length, num_features)),\n",
        "    layers.LSTM(64, activation='tanh'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    X_train, y_train, epochs=200, batch_size=32, validation_split=0.2,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "predictions = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "test_accuracy = np.mean(predictions == y_test)\n",
        "precision = precision_score(y_test, predictions, zero_division=0)\n",
        "recall = recall_score(y_test, predictions, zero_division=0)\n",
        "f1 = f1_score(y_test, predictions, zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, predictions)\n",
        "confusion = confusion_matrix(y_test, predictions)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "r2NksbhjXUpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6143e654-e210-4d54-88db-2642be39dd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 9ms/step\n",
            "[[0.29057485]\n",
            " [0.18620762]\n",
            " [0.24984536]\n",
            " [0.04673165]\n",
            " [0.00792403]\n",
            " [0.03953189]\n",
            " [0.00222253]\n",
            " [0.00224871]\n",
            " [0.00129906]\n",
            " [0.0015697 ]]\n",
            "DO NOT ENTER the trade with a predicted future price of $166.20.\n",
            "Prediction probability: 0.0828\n",
            "Predicted profit/loss: $3.31\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "def predict_next_2_hours_profit(shares, model):\n",
        "    # Fetch recent stock data\n",
        "    latest_data = yf.Ticker(\"AMD\").history(period=\"5d\", interval=\"15m\")\n",
        "\n",
        "    # Calculate features related to time first\n",
        "    latest_data['Hour'] = latest_data.index.hour\n",
        "    latest_data['Minute'] = latest_data.index.minute\n",
        "\n",
        "    # Calculate direct features from stock data\n",
        "    latest_data['PriceRange'] = latest_data['High'] - latest_data['Low']\n",
        "    latest_data['AveragePrice'] = (latest_data['High'] + latest_data['Low'] + latest_data['Close']) / 3\n",
        "    latest_data['MovingAverage'] = latest_data['Close'].rolling(window=3).mean().fillna(latest_data['Close'])\n",
        "\n",
        "    # Calculate lag features\n",
        "    for lag in range(1, 4):\n",
        "        latest_data[f'PriceRange_lag{lag}'] = latest_data['PriceRange'].shift(lag)\n",
        "        latest_data[f'AveragePrice_lag{lag}'] = latest_data['AveragePrice'].shift(lag)\n",
        "        latest_data[f'MovingAverage_lag{lag}'] = latest_data['MovingAverage'].shift(lag)\n",
        "\n",
        "    # Calculate dynamic features that can influence immediate trading decisions\n",
        "    latest_data['Returns'] = latest_data['Close'].pct_change()\n",
        "    latest_data['PriceChange'] = latest_data['Close'].diff()\n",
        "    latest_data['Volatility'] = latest_data['Close'].rolling(window=5).std()\n",
        "    latest_data['Volume'] = latest_data['Volume']\n",
        "    latest_data['PercentIncrease'] = latest_data['Close'].pct_change() * 100\n",
        "\n",
        "    # Drop rows with NaN values which are typically present due to rolling calculations\n",
        "    latest_data.dropna(inplace=True)\n",
        "\n",
        "    # Define feature columns in the desired order for the model input\n",
        "    ordered_feature_columns = [\n",
        "        'Hour', 'Minute',\n",
        "    'PriceRange_lag1', 'AveragePrice_lag1', 'MovingAverage_lag1',\n",
        "    'PriceRange_lag2', 'AveragePrice_lag2', 'MovingAverage_lag2',\n",
        "    'PriceRange_lag3', 'AveragePrice_lag3', 'MovingAverage_lag3',\n",
        "    'PriceRange', 'AveragePrice', 'MovingAverage',\n",
        "    'Returns', 'PriceChange', 'Volatility', 'Volume', 'PercentIncrease'\n",
        "    ]\n",
        "\n",
        "    if len(latest_data) < 15:\n",
        "        raise ValueError(\"Not enough data to make a prediction.\")\n",
        "\n",
        "    # Select and reorder data for the model prediction\n",
        "    latest_features = latest_data[ordered_feature_columns]\n",
        "\n",
        "    # Model prediction\n",
        "    prediction_prob = model.predict(latest_features)[-10:]  # Consider last 10 predictions\n",
        "    print(prediction_prob)\n",
        "    average_prob = prediction_prob.mean()\n",
        "    should_enter_trade = average_prob > 0.5\n",
        "\n",
        "    # Retrieve latest metrics for detailed output\n",
        "    latest_metrics = latest_data.iloc[-1]\n",
        "    close_price = latest_metrics['Close']\n",
        "    average_price = latest_metrics['AveragePrice']\n",
        "    moving_average = latest_metrics['MovingAverage']\n",
        "\n",
        "    # Calculate potential profit or loss\n",
        "    if should_enter_trade:\n",
        "        predicted_future_price = close_price + (2 * average_prob)\n",
        "        predicted_profit = (predicted_future_price - close_price) * shares\n",
        "    else:\n",
        "        predicted_future_price = close_price - (2 * average_prob)\n",
        "        predicted_profit = (close_price - predicted_future_price) * shares\n",
        "\n",
        "    decision = \"enter\" if should_enter_trade else \"DO NOT ENTER\"\n",
        "    print(f\"{decision} the trade with a predicted future price of ${predicted_future_price:.2f}.\")\n",
        "    print(f\"Prediction probability: {average_prob:.4f}\")\n",
        "    print(f\"Predicted profit/loss: ${predicted_profit:.2f}\")\n",
        "\n",
        "\n",
        "    return should_enter_trade, predicted_profit\n",
        "\n",
        "# Usage example\n",
        "try:\n",
        "    shares = 20\n",
        "    should_enter_trade, predicted_profit = predict_next_2_hours_profit(shares, model)\n",
        "except ValueError as e:\n",
        "    print(f\"Error making prediction: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}